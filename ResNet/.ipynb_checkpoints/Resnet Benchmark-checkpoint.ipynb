{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "clear-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# use Keras to import pre-shuffled MNIST database\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infrared-scanner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# normalize the data to accelerate learning\n",
    "mean = np.mean(X_train)\n",
    "std = np.std(X_train)\n",
    "X_train = (X_train-mean)/(std+1e-7)\n",
    "X_test = (X_test-mean)/(std+1e-7)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustained-apple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer-valued labels:\n",
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "One-hot labels:\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "num_classes = 10 \n",
    "# print first ten (integer-valued) training labels\n",
    "print('Integer-valued labels:')\n",
    "print(y_train[:10])\n",
    "\n",
    "# one-hot encode the labels\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# print first ten (one-hot) training labels\n",
    "print('One-hot labels:')\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alive-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image input shape:  (28, 28, 1)\n",
      "x_train shape: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions 28x28 pixel images. \n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('image input shape: ', input_shape)\n",
    "print('x_train shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coral-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "small-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(input_shape = (28,28,1), classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "completed-ireland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 11, 11, 64)   3200        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 11, 11, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 11, 11, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 64)     0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_1/conv_a (Conv2D)        (None, 5, 5, 64)     4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_1/norm_a (BatchNormaliza (None, 5, 5, 64)     256         Stage2_1/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 5, 5, 64)     0           Stage2_1/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_1/conv_b (Conv2D)        (None, 5, 5, 64)     36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_1/norm_b (BatchNormaliza (None, 5, 5, 64)     256         Stage2_1/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 5, 5, 64)     0           Stage2_1/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_1/conv_c (Conv2D)        (None, 5, 5, 256)    16640       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_11 (Conv2D)              (None, 5, 5, 256)    16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_1/norm_c (BatchNormaliza (None, 5, 5, 256)    1024        Stage2_1/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_1norm1 (BatchNormalizati (None, 5, 5, 256)    1024        Stage2_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 5, 5, 256)    0           Stage2_1/norm_c[0][0]            \n",
      "                                                                 Stage2_1norm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5, 5, 256)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_2/conv_a (Conv2D)        (None, 5, 5, 64)     16448       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_2/norm_a (BatchNormaliza (None, 5, 5, 64)     256         Stage2_2/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 5, 5, 64)     0           Stage2_2/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_2/conv_b (Conv2D)        (None, 5, 5, 64)     36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_2/norm_b (BatchNormaliza (None, 5, 5, 64)     256         Stage2_2/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 5, 5, 64)     0           Stage2_2/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_2/conv_c (Conv2D)        (None, 5, 5, 256)    16640       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_2/norm_c (BatchNormaliza (None, 5, 5, 256)    1024        Stage2_2/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 5, 5, 256)    0           Stage2_2/norm_c[0][0]            \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 5, 5, 256)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_3/conv_a (Conv2D)        (None, 5, 5, 64)     16448       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_3/norm_a (BatchNormaliza (None, 5, 5, 64)     256         Stage2_3/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 5, 5, 64)     0           Stage2_3/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_3/conv_b (Conv2D)        (None, 5, 5, 64)     36928       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_3/norm_b (BatchNormaliza (None, 5, 5, 64)     256         Stage2_3/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 5, 5, 64)     0           Stage2_3/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_3/conv_c (Conv2D)        (None, 5, 5, 256)    16640       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage2_3/norm_c (BatchNormaliza (None, 5, 5, 256)    1024        Stage2_3/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 5, 5, 256)    0           Stage2_3/norm_c[0][0]            \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 5, 5, 256)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_1/conv_a (Conv2D)        (None, 3, 3, 128)    32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_1/norm_a (BatchNormaliza (None, 3, 3, 128)    512         Stage3_1/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 3, 3, 128)    0           Stage3_1/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_1/conv_b (Conv2D)        (None, 3, 3, 128)    147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_1/norm_b (BatchNormaliza (None, 3, 3, 128)    512         Stage3_1/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 3, 3, 128)    0           Stage3_1/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_1/conv_c (Conv2D)        (None, 3, 3, 512)    66048       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_11 (Conv2D)              (None, 3, 3, 512)    131584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_1/norm_c (BatchNormaliza (None, 3, 3, 512)    2048        Stage3_1/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_1norm1 (BatchNormalizati (None, 3, 3, 512)    2048        Stage3_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 3, 3, 512)    0           Stage3_1/norm_c[0][0]            \n",
      "                                                                 Stage3_1norm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 3, 3, 512)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_2/conv_a (Conv2D)        (None, 3, 3, 128)    65664       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_2/norm_a (BatchNormaliza (None, 3, 3, 128)    512         Stage3_2/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 3, 3, 128)    0           Stage3_2/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_2/conv_b (Conv2D)        (None, 3, 3, 128)    147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_2/norm_b (BatchNormaliza (None, 3, 3, 128)    512         Stage3_2/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 3, 3, 128)    0           Stage3_2/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_2/conv_c (Conv2D)        (None, 3, 3, 512)    66048       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_2/norm_c (BatchNormaliza (None, 3, 3, 512)    2048        Stage3_2/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 3, 3, 512)    0           Stage3_2/norm_c[0][0]            \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 3, 3, 512)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_3/conv_a (Conv2D)        (None, 3, 3, 128)    65664       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_3/norm_a (BatchNormaliza (None, 3, 3, 128)    512         Stage3_3/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 3, 3, 128)    0           Stage3_3/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_3/conv_b (Conv2D)        (None, 3, 3, 128)    147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_3/norm_b (BatchNormaliza (None, 3, 3, 128)    512         Stage3_3/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 3, 3, 128)    0           Stage3_3/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_3/conv_c (Conv2D)        (None, 3, 3, 512)    66048       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_3/norm_c (BatchNormaliza (None, 3, 3, 512)    2048        Stage3_3/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 3, 3, 512)    0           Stage3_3/norm_c[0][0]            \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 3, 3, 512)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_4/conv_a (Conv2D)        (None, 3, 3, 128)    65664       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_4/norm_a (BatchNormaliza (None, 3, 3, 128)    512         Stage3_4/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 3, 3, 128)    0           Stage3_4/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_4/conv_b (Conv2D)        (None, 3, 3, 128)    147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_4/norm_b (BatchNormaliza (None, 3, 3, 128)    512         Stage3_4/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 3, 3, 128)    0           Stage3_4/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_4/conv_c (Conv2D)        (None, 3, 3, 512)    66048       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage3_4/norm_c (BatchNormaliza (None, 3, 3, 512)    2048        Stage3_4/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 3, 3, 512)    0           Stage3_4/norm_c[0][0]            \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 3, 3, 512)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_1/conv_a (Conv2D)        (None, 2, 2, 256)    131328      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_1/norm_a (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_1/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 256)    0           Stage4_1/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_1/conv_b (Conv2D)        (None, 2, 2, 256)    590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_1/norm_b (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_1/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 256)    0           Stage4_1/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_1/conv_c (Conv2D)        (None, 2, 2, 1024)   263168      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_11 (Conv2D)              (None, 2, 2, 1024)   525312      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_1/norm_c (BatchNormaliza (None, 2, 2, 1024)   4096        Stage4_1/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_1norm1 (BatchNormalizati (None, 2, 2, 1024)   4096        Stage4_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 2, 2, 1024)   0           Stage4_1/norm_c[0][0]            \n",
      "                                                                 Stage4_1norm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 2, 2, 1024)   0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_2/conv_a (Conv2D)        (None, 2, 2, 256)    262400      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_2/norm_a (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_2/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 2, 2, 256)    0           Stage4_2/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_2/conv_b (Conv2D)        (None, 2, 2, 256)    590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_2/norm_b (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_2/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 256)    0           Stage4_2/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_2/conv_c (Conv2D)        (None, 2, 2, 1024)   263168      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_2/norm_c (BatchNormaliza (None, 2, 2, 1024)   4096        Stage4_2/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 2, 2, 1024)   0           Stage4_2/norm_c[0][0]            \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 1024)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_3/conv_a (Conv2D)        (None, 2, 2, 256)    262400      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_3/norm_a (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_3/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 256)    0           Stage4_3/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_3/conv_b (Conv2D)        (None, 2, 2, 256)    590080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_3/norm_b (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_3/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 256)    0           Stage4_3/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_3/conv_c (Conv2D)        (None, 2, 2, 1024)   263168      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_3/norm_c (BatchNormaliza (None, 2, 2, 1024)   4096        Stage4_3/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2, 2, 1024)   0           Stage4_3/norm_c[0][0]            \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 1024)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_4/conv_a (Conv2D)        (None, 2, 2, 256)    262400      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_4/norm_a (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_4/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 256)    0           Stage4_4/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_4/conv_b (Conv2D)        (None, 2, 2, 256)    590080      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_4/norm_b (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_4/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 256)    0           Stage4_4/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_4/conv_c (Conv2D)        (None, 2, 2, 1024)   263168      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_4/norm_c (BatchNormaliza (None, 2, 2, 1024)   4096        Stage4_4/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 2, 2, 1024)   0           Stage4_4/norm_c[0][0]            \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 1024)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_5/conv_a (Conv2D)        (None, 2, 2, 256)    262400      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_5/norm_a (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_5/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 256)    0           Stage4_5/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_5/conv_b (Conv2D)        (None, 2, 2, 256)    590080      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_5/norm_b (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_5/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 256)    0           Stage4_5/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_5/conv_c (Conv2D)        (None, 2, 2, 1024)   263168      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_5/norm_c (BatchNormaliza (None, 2, 2, 1024)   4096        Stage4_5/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 2, 2, 1024)   0           Stage4_5/norm_c[0][0]            \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_6/conv_a (Conv2D)        (None, 2, 2, 256)    262400      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_6/norm_a (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_6/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 256)    0           Stage4_6/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_6/conv_b (Conv2D)        (None, 2, 2, 256)    590080      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_6/norm_b (BatchNormaliza (None, 2, 2, 256)    1024        Stage4_6/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 256)    0           Stage4_6/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_6/conv_c (Conv2D)        (None, 2, 2, 1024)   263168      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage4_6/norm_c (BatchNormaliza (None, 2, 2, 1024)   4096        Stage4_6/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2, 2, 1024)   0           Stage4_6/norm_c[0][0]            \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 1024)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_1/conv_a (Conv2D)        (None, 1, 1, 512)    524800      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_1/norm_a (BatchNormaliza (None, 1, 1, 512)    2048        Stage5_1/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 1, 1, 512)    0           Stage5_1/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_1/conv_b (Conv2D)        (None, 1, 1, 512)    2359808     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_1/norm_b (BatchNormaliza (None, 1, 1, 512)    2048        Stage5_1/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 1, 1, 512)    0           Stage5_1/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_1/conv_c (Conv2D)        (None, 1, 1, 2048)   1050624     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_11 (Conv2D)              (None, 1, 1, 2048)   2099200     activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_1/norm_c (BatchNormaliza (None, 1, 1, 2048)   8192        Stage5_1/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_1norm1 (BatchNormalizati (None, 1, 1, 2048)   8192        Stage5_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1, 1, 2048)   0           Stage5_1/norm_c[0][0]            \n",
      "                                                                 Stage5_1norm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 1, 1, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_2/conv_a (Conv2D)        (None, 1, 1, 512)    1049088     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_2/norm_a (BatchNormaliza (None, 1, 1, 512)    2048        Stage5_2/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 1, 1, 512)    0           Stage5_2/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_2/conv_b (Conv2D)        (None, 1, 1, 512)    2359808     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_2/norm_b (BatchNormaliza (None, 1, 1, 512)    2048        Stage5_2/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 1, 1, 512)    0           Stage5_2/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_2/conv_c (Conv2D)        (None, 1, 1, 2048)   1050624     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_2/norm_c (BatchNormaliza (None, 1, 1, 2048)   8192        Stage5_2/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 1, 1, 2048)   0           Stage5_2/norm_c[0][0]            \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 1, 1, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_3/conv_a (Conv2D)        (None, 1, 1, 512)    1049088     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_3/norm_a (BatchNormaliza (None, 1, 1, 512)    2048        Stage5_3/conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 1, 1, 512)    0           Stage5_3/norm_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_3/conv_b (Conv2D)        (None, 1, 1, 512)    2359808     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_3/norm_b (BatchNormaliza (None, 1, 1, 512)    2048        Stage5_3/conv_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 1, 1, 512)    0           Stage5_3/norm_b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_3/conv_c (Conv2D)        (None, 1, 1, 2048)   1050624     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stage5_3/norm_c (BatchNormaliza (None, 1, 1, 2048)   8192        Stage5_3/conv_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 1, 1, 2048)   0           Stage5_3/norm_c[0][0]            \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 1, 1, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           20490       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,601,930\n",
      "Trainable params: 23,548,810\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "violent-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 80/235 [=========>....................] - ETA: 14:32 - loss: 1.9752 - accuracy: 0.4819"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ecfbfe171716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                      metrics=['accuracy'], )                                           \n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m history = resnet.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_test, y_test),\n\u001b[0m\u001b[0;32m     24\u001b[0m           epochs=epochs, callbacks=[callback[\"check_point\"]])   \n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "epochs = 2                                                         \n",
    "batch_size = 256                                                     \n",
    "\n",
    "callback = {\"early_stopping\": EarlyStopping(patience=3, monitor=\"val_loss\", restore_best_weights=False),\n",
    "            \"tensorboard\"   : tf.keras.callbacks.TensorBoard(log_dir=log_dir), # %load_ext tensorboard, %tensorboard --logdir logs\n",
    "            \"reduce_lr\"     : ReduceLROnPlateau(monitor='val_loss',factor=np.sqrt(0.1), patience=5, min_lr=0.5e-6),\n",
    "            \"check_point\"   : ModelCheckpoint(\"model\", save_best_only=True, verbose=1),\n",
    "            \"log_csv\"       : CSVLogger(\"training.csv\") \n",
    "           }\n",
    "\n",
    "resnet.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                     optimizer=\"Adam\",\n",
    "                     metrics=['accuracy'], )                                           \n",
    " \n",
    "history = resnet.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_test, y_test),\n",
    "          epochs=epochs, callbacks=[callback[\"check_point\"]])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cooperative-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_metrics(metric_name, title):\n",
    "    plt.title(title)\n",
    "    #plt.ylim(0, ylim)\n",
    "    plt.plot(history.history[metric_name], color='blue', label=metric_name)\n",
    "    plt.plot(history.history['val_' + metric_name], color='green', label='val_' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intermediate-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(\"accuracy\", \"loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
